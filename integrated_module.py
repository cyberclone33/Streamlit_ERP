# éŠ·è²¨å–®èˆ‡BCç”¢å“è³‡æ–™æ•´åˆæ¨¡çµ„ - Sales and BC Products Integrated Module
import streamlit as st
import pandas as pd
import os
import importlib
import sales
import bc_products
import plotly.express as px
from datetime import datetime
import locale
import numpy as np
import shutil

# Set locale for proper number formatting
try:
    locale.setlocale(locale.LC_ALL, 'zh_TW.UTF-8')  # For Taiwan locale
except:
    try:
        locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')  # Fallback to US locale
    except:
        pass  # Keep default locale if unable to set

# Set page configuration only when run as standalone (not imported)
if __name__ == "__main__":
    st.set_page_config(
        page_title="éŠ·è²¨å–®èˆ‡BCç”¢å“è³‡æ–™æ•´åˆ",
        page_icon="ğŸ”„",
        layout="wide",
        initial_sidebar_state="collapsed"
    )

# Function to get files sorted by modification time
def get_sorted_files(directory, file_extension=".xlsx"):
    """Get files from directory sorted by modification time (newest first)"""
    if not os.path.exists(directory):
        return []
    
    # Get files with their modification times
    files_with_time = [(f, os.path.getmtime(os.path.join(directory, f))) 
                      for f in os.listdir(directory) if f.endswith(file_extension)]
    
    # Sort by modification time, newest first
    files_with_time.sort(key=lambda x: x[1], reverse=True)
    
    # Return sorted filenames
    return [f[0] for f in files_with_time]

# Function to get all available files (both active and uploads)
def get_all_available_files(main_dir, uploads_dir, file_extension=".xlsx"):
    """Get all available files from both main and uploads directories"""
    main_files = get_sorted_files(main_dir, file_extension)
    uploads_files = get_sorted_files(uploads_dir, file_extension)
    
    # Create a set of main files to check for duplicates
    main_files_set = set(main_files)
    
    # Add upload files that aren't already in main directory
    all_files = main_files.copy()
    for f in uploads_files:
        if f not in main_files_set:
            all_files.append(f)
    
    return all_files, main_files, uploads_files

# Main function for the integrated module
def run_integrated_analysis():
    # Initialize session states for file selection
    if 'integrated_sales_periods' not in st.session_state:
        st.session_state.integrated_sales_periods = []
    if 'integrated_bc_file' not in st.session_state:
        st.session_state.integrated_bc_file = None
    if 'show_upload_history' not in st.session_state:
        st.session_state.show_upload_history = False
    
    # Title with refresh button
    title_col, refresh_col = st.columns([5, 1])
    with title_col:
        st.title("éŠ·è²¨å–®èˆ‡BCç”¢å“è³‡æ–™æ•´åˆåˆ†æ")
    with refresh_col:
        if st.button("ğŸ”„ é‡æ–°æ•´ç†", key="refresh_integrated", help="é‡æ–°æ•´ç†æª”æ¡ˆæ¸…å–®èˆ‡è³‡æ–™"):
            # Clear cached data
            sales.load_data.clear() if hasattr(sales.load_data, 'clear') else None
            bc_products.load_data.clear() if hasattr(bc_products.load_data, 'clear') else None
            st.rerun()
    
    # Get directories for both data types
    sales_data_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "sales data")
    sales_uploads_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "uploads/sales")
    bc_products_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "bc  products")
    bc_uploads_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "uploads/bc_products")
    
    # Toggle for showing upload history
    show_uploads = st.checkbox("é¡¯ç¤ºä¸Šå‚³æ­·å²æª”æ¡ˆ", 
                               value=st.session_state.show_upload_history,
                               help="é¸æ“‡æ˜¯å¦åŒ…å«ä¸Šå‚³æ­·å²ä¸­çš„æª”æ¡ˆ")
    st.session_state.show_upload_history = show_uploads
    
    # Sales data section
    st.header("éŠ·è²¨å–®æ¯›åˆ©åˆ†æè³‡æ–™é¸æ“‡")
    
    # Get all sales files
    if show_uploads:
        all_sales_files, active_sales_files, upload_sales_files = get_all_available_files(sales_data_dir, sales_uploads_dir)
        
        # Show counts of files
        st.info(f"å…±æœ‰ {len(active_sales_files)} å€‹ä½¿ç”¨ä¸­æª”æ¡ˆ + {len(upload_sales_files)} å€‹ä¸Šå‚³æ­·å²æª”æ¡ˆ")
        
        # Mark files from upload history
        display_options = {}
        for file in all_sales_files:
            label = sales.extract_date_from_filename(file)
            
            # Add indicator if file is from upload history
            if file not in active_sales_files:
                label = f"{label} [ä¸Šå‚³æ­·å²]"
                
                # Add button to activate file
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.text(file)
                with col2:
                    if st.button("å•Ÿç”¨æ­¤æª”æ¡ˆ", key=f"activate_{file}"):
                        try:
                            # Copy from uploads to active directory
                            shutil.copy(
                                os.path.join(sales_uploads_dir, file),
                                os.path.join(sales_data_dir, file)
                            )
                            st.success(f"å·²å•Ÿç”¨ {file}")
                            st.rerun()
                        except Exception as e:
                            st.error(f"ç„¡æ³•å•Ÿç”¨æª”æ¡ˆ: {e}")
            
            display_options[label] = file
    else:
        # Only use active files
        active_sales_files = get_sorted_files(sales_data_dir)
        display_options = {sales.extract_date_from_filename(file): file for file in active_sales_files}
    
    # Get the sorted keys
    sorted_keys = sorted(display_options.keys())
    
    # Determine default selection based on session state
    default_periods = []
    if st.session_state.integrated_sales_periods:
        # Use stored selections if they exist
        for period in st.session_state.integrated_sales_periods:
            if period in sorted_keys:
                default_periods.append(period)
    
    # If no stored options or they're invalid, default to first item
    if not default_periods and sorted_keys:
        default_periods = [sorted_keys[0]]
    
    # Using multi-month selection
    selected_periods = st.multiselect(
        "é¸æ“‡å¤šå€‹å ±è¡¨æœŸé–“ (æŒ‰ä½Ctrlæˆ–âŒ˜éµå¯å¤šé¸)",
        options=sorted_keys,
        default=default_periods
    )
    
    # Save to session state
    st.session_state.integrated_sales_periods = selected_periods
    
    # Check if any periods are selected
    if not selected_periods:
        st.warning("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹å ±è¡¨æœŸé–“")
        sales_df = None
        period_display = None
    else:
        # Load data from multiple months, keeping track of which month each record belongs to
        dfs = []
        monthly_dfs = {}  # Dictionary to store each month's dataframe
        
        for period in selected_periods:
            file = display_options.get(period)
            
            # Determine the correct directory for this file
            if show_uploads and file not in active_sales_files:
                # File is from upload history
                file_path = os.path.join(sales_uploads_dir, file)
            else:
                # File is from active directory
                file_path = os.path.join(sales_data_dir, file)
            
            # Load the dataframe for this period
            period_df = sales.load_data(file_path)
            
            # Add a period identifier column
            period_df['_period'] = period
            
            # Store in our collection
            dfs.append(period_df)
            monthly_dfs[period] = period_df
        
        # Store the monthly dataframes in session state for later use
        st.session_state.monthly_sales_dfs = monthly_dfs
        st.session_state.selected_periods = selected_periods
        
        # Combine all dataframes
        sales_df = pd.concat(dfs, ignore_index=True)
        
        # Display combined periods
        period_display = f"åˆä½µå ±è¡¨ ({', '.join(selected_periods)})"
        
        # Show selected period
        st.subheader(f"æœŸé–“: {period_display}")
    
    # BC Products data section
    st.header("BCç”¢å“å…¨éƒ¨è³‡æ–™é¸æ“‡")
    
    # Get BC products data with uploads if requested
    try:
        if show_uploads:
            all_bc_files, active_bc_files, upload_bc_files = get_all_available_files(bc_products_dir, bc_uploads_dir)
            
            # Show counts of files
            st.info(f"å…±æœ‰ {len(active_bc_files)} å€‹ä½¿ç”¨ä¸­æª”æ¡ˆ + {len(upload_bc_files)} å€‹ä¸Šå‚³æ­·å²æª”æ¡ˆ")
            
            # Mark files from upload history
            display_bc_options = []
            for file in all_bc_files:
                # Add indicator if file is from upload history
                if file not in active_bc_files:
                    # Add button to activate file
                    col1, col2 = st.columns([4, 1])
                    with col1:
                        st.text(f"{file} [ä¸Šå‚³æ­·å²]")
                    with col2:
                        if st.button("å•Ÿç”¨æ­¤æª”æ¡ˆ", key=f"activate_bc_{file}"):
                            try:
                                # Copy from uploads to active directory
                                shutil.copy(
                                    os.path.join(bc_uploads_dir, file),
                                    os.path.join(bc_products_dir, file)
                                )
                                st.success(f"å·²å•Ÿç”¨ {file}")
                                st.rerun()
                            except Exception as e:
                                st.error(f"ç„¡æ³•å•Ÿç”¨æª”æ¡ˆ: {e}")
                
                display_bc_options.append(file)
        else:
            # Only use active files
            display_bc_options = get_sorted_files(bc_products_dir)
        
        if not display_bc_options:
            st.error("æ²’æœ‰æ‰¾åˆ°ç”¢å“è³‡æ–™æª”æ¡ˆ")
            bc_df = None
            file_date_formatted = None
        else:
            # Determine default selection
            default_index = 0
            if st.session_state.integrated_bc_file in display_bc_options:
                default_index = display_bc_options.index(st.session_state.integrated_bc_file)
            
            selected_file = st.selectbox(
                "é¸æ“‡ç”¢å“è³‡æ–™æª”æ¡ˆ:", 
                display_bc_options,
                index=default_index
            )
            
            # Save to session state
            st.session_state.integrated_bc_file = selected_file
            
            # Determine correct directory
            if show_uploads and selected_file not in active_bc_files:
                file_path = os.path.join(bc_uploads_dir, selected_file)
            else:
                file_path = os.path.join(bc_products_dir, selected_file)
            
            # Add file modification time
            file_mod_time = datetime.fromtimestamp(os.path.getmtime(file_path))
            st.info(f"æª”æ¡ˆæ›´æ–°æ™‚é–“: {file_mod_time.strftime('%Y-%m-%d %H:%M:%S')}")
            
            # Load data
            bc_df = bc_products.load_data(file_path)
            
            # Extract file date for display
            try:
                file_date = selected_file.split('_')[-1].replace('.xlsx', '')
                # Make sure the date format is valid
                if len(file_date) >= 8:  # At least YYYYMMDD format
                    file_date_formatted = f"{file_date[:4]}/{file_date[4:6]}/{file_date[6:8]}"
                else:
                    # If date is not in expected format, use file modification time
                    file_date_formatted = file_mod_time.strftime("%Y/%m/%d")
            except:
                # Fallback to modification time if parsing fails
                file_date_formatted = file_mod_time.strftime("%Y/%m/%d")
    except Exception as e:
        st.error(f"è®€å–BCç”¢å“è³‡æ–™éŒ¯èª¤: {e}")
        bc_df = None
        file_date_formatted = None
    
    return sales_df, period_display, bc_df, file_date_formatted

# Function to display integrated dashboard
def display_integrated_dashboard(sales_df, period_display, bc_df, file_date):
    # Add refresh button to refresh cache
    refresh_col1, refresh_col2 = st.columns([4, 1])
    with refresh_col1:
        st.markdown("### è³‡æ–™ç‹€æ…‹:")
    with refresh_col2:
        if st.button("ğŸ”„ é‡æ–°è¼‰å…¥è³‡æ–™", key="refresh_data", help="æ¸…é™¤è³‡æ–™å¿«å–ä¸¦é‡æ–°è¼‰å…¥"):
            # Clear caches
            sales.load_data.clear() if hasattr(sales.load_data, 'clear') else None
            bc_products.load_data.clear() if hasattr(bc_products.load_data, 'clear') else None
            st.rerun()
    
    # Show data status with modification time information
    st.markdown("---")
    col1, col2 = st.columns(2)
    
    with col1:
        if sales_df is not None:
            st.success(f"âœ… éŠ·è²¨å–®è³‡æ–™å·²è¼‰å…¥: {period_display}")
            if st.session_state.show_upload_history:
                st.info("âœ“ ä¸Šå‚³æ­·å²æª”æ¡ˆå¯ç”¨")
            if hasattr(st.session_state, 'integrated_sales_periods'):
                st.info(f"é¸æ“‡å ±è¡¨: {', '.join(st.session_state.integrated_sales_periods)}")
        else:
            st.error("âŒ éŠ·è²¨å–®è³‡æ–™æœªè¼‰å…¥")
    
    with col2:
        if bc_df is not None:
            st.success(f"âœ… BCç”¢å“è³‡æ–™å·²è¼‰å…¥: {file_date}")
            if hasattr(st.session_state, 'integrated_bc_file'):
                st.info(f"æª”æ¡ˆ: {st.session_state.integrated_bc_file}")
        else:
            st.error("âŒ BCç”¢å“è³‡æ–™æœªè¼‰å…¥")
    
    # Add checkbox to toggle upload history
    change_col1, change_col2 = st.columns(2)
    with change_col1:
        if st.button("æ›´æ”¹éŠ·è²¨å–®è³‡æ–™é¸æ“‡"):
            # Move back to the top of the page
            st.session_state._is_uploading = True
            st.experimental_set_query_params(section="sales_data")
            st.rerun()
    
    with change_col2:
        if st.button("æ›´æ”¹BCç”¢å“è³‡æ–™é¸æ“‡"):
            # Move back to the top of the page
            st.session_state._is_uploading = True
            st.experimental_set_query_params(section="bc_data")
            st.rerun()
            
    st.markdown("---")
    
    # Only proceed if we have valid data
    if sales_df is None:
        st.warning("è«‹å…ˆé¸æ“‡éŠ·è²¨å–®è³‡æ–™")
        return
    
    # Display product summary table from sales data (reusing code from sales.py)
    st.header("éŠ·è²¨å–®ç”¢å“å½™ç¸½è¡¨")

    # Add product code filter for sales data
    product_code_filter = st.text_input("è¼¸å…¥ç”¢å“ä»£è™Ÿé€²è¡Œç¯©é¸ (ç•™ç©ºé¡¯ç¤ºå…¨éƒ¨):", "")

    # Make a copy of the dataframe to clean numeric columns first
    df_products = sales_df.copy()

    # Fill in order information using the function from sales module
    sales_df_filled = sales.fill_order_info(sales_df)

    # Create a filtered version of the raw data if product code is provided
    if product_code_filter:
        # ä½¿ç”¨å¡«å……å¾Œçš„DataFrameé€²è¡Œç¯©é¸ï¼Œç¢ºä¿é¡¯ç¤ºå®Œæ•´è¨‚å–®è³‡è¨Š
        df_filtered_raw = sales_df_filled[sales_df_filled['ç”¢å“ä»£è™Ÿ'].str.contains(product_code_filter, case=False, na=False)]

        if df_filtered_raw.empty:
            st.warning(f"æ²’æœ‰æ‰¾åˆ°åŒ…å« '{product_code_filter}' çš„ç”¢å“ä»£è™Ÿ")
        else:
            st.success(f"æ‰¾åˆ° {len(df_filtered_raw)} ç­†åŒ…å« '{product_code_filter}' çš„äº¤æ˜“è¨˜éŒ„")

            # æ·»åŠ èªªæ˜
            st.info("æ³¨æ„: åŒä¸€è¨‚å–®ä¸­çš„æ‰€æœ‰ç”¢å“è¡Œå·²è‡ªå‹•å¡«å……è¨‚å–®è³‡è¨Šï¼Œä»¥ç¢ºä¿é¡¯ç¤ºå®Œæ•´è³‡æ–™ã€‚")

            # Show the filtered raw data with filled order information
            with st.expander("æŸ¥çœ‹ç¯©é¸å¾Œçš„åŸå§‹äº¤æ˜“è¨˜éŒ„ (å·²å¡«å……è¨‚å–®è³‡è¨Š)", expanded=True):
                st.dataframe(df_filtered_raw, use_container_width=True)

    # Ensure numeric columns are properly converted to numeric before aggregation
    numeric_cols = ['æ•¸é‡', 'å°è¨ˆ', 'æˆæœ¬ç¸½å€¼']
    for col in numeric_cols:
        if col in df_products.columns:
            if df_products[col].dtype == 'object':
                df_products[col] = df_products[col].astype(str).str.replace(',', '')
                df_products[col] = pd.to_numeric(df_products[col], errors='coerce')
    
    # Separate handling for unit price
    if 'å–®åƒ¹' in df_products.columns:
        if df_products['å–®åƒ¹'].dtype == 'object':
            df_products['å–®åƒ¹'] = df_products['å–®åƒ¹'].astype(str).str.replace(',', '')
            df_products['å–®åƒ¹'] = pd.to_numeric(df_products['å–®åƒ¹'], errors='coerce')
    
    # Apply filter to products data if needed
    if product_code_filter:
        df_products_filtered = df_products[df_products['ç”¢å“ä»£è™Ÿ'].str.contains(product_code_filter, case=False, na=False)]
    else:
        df_products_filtered = df_products.copy()

    # Now do the aggregation on filtered data with better error handling
    # First create a dict of aggregation functions for columns that exist
    agg_dict = {}
    if 'ç”¢å“åç¨±' in df_products_filtered.columns:
        agg_dict['ç”¢å“åç¨±'] = 'first'  # Take the first product name
    
    if 'æ•¸é‡' in df_products_filtered.columns:
        agg_dict['æ•¸é‡'] = 'sum'        # Sum quantities
    
    if 'å–®ä½' in df_products_filtered.columns:
        agg_dict['å–®ä½'] = 'first'      # Take the first unit
    
    if 'å–®åƒ¹' in df_products_filtered.columns:
        agg_dict['å–®åƒ¹'] = 'mean'       # Average price
    
    if 'å°è¨ˆ' in df_products_filtered.columns:
        agg_dict['å°è¨ˆ'] = 'sum'        # Sum subtotals
    
    if 'æˆæœ¬ç¸½å€¼' in df_products_filtered.columns:
        agg_dict['æˆæœ¬ç¸½å€¼'] = 'sum'     # Sum cost values
    
    # Only proceed if we have some columns to aggregate
    if agg_dict and 'ç”¢å“ä»£è™Ÿ' in df_products_filtered.columns:
        # Do the aggregation
        product_summary = df_products_filtered.groupby(['ç”¢å“ä»£è™Ÿ'], as_index=False).agg(agg_dict)
        
        # Sort by å°è¨ˆ in descending order if it exists
        if 'å°è¨ˆ' in product_summary.columns:
            product_summary = product_summary.sort_values(by='å°è¨ˆ', ascending=False)
        
        # Calculate å–®åƒ¹ï¼ˆæ•¸é‡ï¼‰= å°è¨ˆ / æ•¸é‡ safely
        # Initialize the column with float type to avoid dtype incompatibility
        product_summary['å–®åƒ¹ï¼ˆæ•¸é‡ï¼‰'] = 0.0  # Default value as float
        if 'æ•¸é‡' in product_summary.columns and 'å°è¨ˆ' in product_summary.columns:
            # Use vectorized operations with safety checks
            mask = product_summary['æ•¸é‡'] > 0
            if isinstance(mask, pd.Series) and mask.any():
                # Calculate the division result as float
                result = (
                    product_summary.loc[mask, 'å°è¨ˆ'] / product_summary.loc[mask, 'æ•¸é‡']
                ).astype('float64')  # Explicitly convert to float64
                # Assign the result to the column
                product_summary.loc[mask, 'å–®åƒ¹ï¼ˆæ•¸é‡ï¼‰'] = result
        
        # Add monthly breakdowns if we have multiple periods selected
        if hasattr(st.session_state, 'monthly_sales_dfs') and len(st.session_state.monthly_sales_dfs) > 0:
            monthly_dfs = st.session_state.monthly_sales_dfs
            selected_periods = st.session_state.selected_periods
            
            # Process each month's data separately
            for period in selected_periods:
                if period in monthly_dfs:
                    period_df = monthly_dfs[period]
                    
                    # Create a copy and ensure numeric columns are properly converted
                    period_products = period_df.copy()
                    for col in numeric_cols:
                        if col in period_products.columns:
                            if period_products[col].dtype == 'object':
                                period_products[col] = period_products[col].astype(str).str.replace(',', '')
                                period_products[col] = pd.to_numeric(period_products[col], errors='coerce')
                    
                    # Also handle unit price for this period
                    if 'å–®åƒ¹' in period_products.columns and period_products['å–®åƒ¹'].dtype == 'object':
                        period_products['å–®åƒ¹'] = period_products['å–®åƒ¹'].astype(str).str.replace(',', '')
                        period_products['å–®åƒ¹'] = pd.to_numeric(period_products['å–®åƒ¹'], errors='coerce')
                    
                    # Apply product code filter if needed
                    if product_code_filter:
                        period_products = period_products[
                            period_products['ç”¢å“ä»£è™Ÿ'].str.contains(product_code_filter, case=False, na=False)
                        ]
                    
                    # Create period-specific aggregation
                    period_agg = {}
                    if 'æ•¸é‡' in period_products.columns:
                        period_agg['æ•¸é‡'] = 'sum'
                    if 'å°è¨ˆ' in period_products.columns:
                        period_agg['å°è¨ˆ'] = 'sum'
                    
                    # Only proceed if we have data to aggregate
                    if period_agg and 'ç”¢å“ä»£è™Ÿ' in period_products.columns:
                        try:
                            # Create period summary
                            period_summary = period_products.groupby(['ç”¢å“ä»£è™Ÿ'], as_index=False).agg(period_agg)
                            
                            # Rename columns to include period
                            if 'æ•¸é‡' in period_summary.columns:
                                period_summary.rename(columns={'æ•¸é‡': f'{period} éŠ·å”®æ•¸é‡'}, inplace=True)
                            if 'å°è¨ˆ' in period_summary.columns:
                                period_summary.rename(columns={'å°è¨ˆ': f'{period} éŠ·å”®å°è¨ˆ'}, inplace=True)
                            
                            # Merge with main product summary
                            product_summary = pd.merge(
                                product_summary, 
                                period_summary, 
                                on='ç”¢å“ä»£è™Ÿ', 
                                how='left'
                            )
                            
                            # Fill NaN values with 0
                            if f'{period} éŠ·å”®æ•¸é‡' in product_summary.columns:
                                product_summary[f'{period} éŠ·å”®æ•¸é‡'].fillna(0, inplace=True)
                            if f'{period} éŠ·å”®å°è¨ˆ' in product_summary.columns:
                                product_summary[f'{period} éŠ·å”®å°è¨ˆ'].fillna(0, inplace=True)
                        except Exception as e:
                            st.warning(f"è™•ç† {period} æœŸé–“çš„éŠ·å”®æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    else:
        # Create an empty DataFrame with expected columns if aggregation isn't possible
        product_summary = pd.DataFrame(columns=['ç”¢å“ä»£è™Ÿ', 'ç”¢å“åç¨±', 'æ•¸é‡', 'å–®ä½', 'å–®åƒ¹', 'å°è¨ˆ', 'æˆæœ¬ç¸½å€¼', 'å–®åƒ¹ï¼ˆæ•¸é‡ï¼‰'])

    # Add inventory column (åº«å­˜) if we have BC products data
    if bc_df is not None and 'ç”¢å“ä»£è™Ÿ' in bc_df.columns and 'æ•¸é‡' in bc_df.columns:
        # Create a simple mapping of product code to inventory quantity
        inventory_map = {}
        # Ensure æ•¸é‡ is numeric in BC data
        if bc_df['æ•¸é‡'].dtype == 'object':
            bc_df['æ•¸é‡'] = pd.to_numeric(bc_df['æ•¸é‡'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)

        inventory_map = dict(zip(bc_df['ç”¢å“ä»£è™Ÿ'], bc_df['æ•¸é‡']))

        # Map inventory data to product summary
        # Ensure proper type conversion to avoid incompatible dtype warning
        # First convert to float, then to int to handle any non-integer values
        product_summary['åº«å­˜'] = product_summary['ç”¢å“ä»£è™Ÿ'].map(inventory_map).fillna(0).astype(float).astype(int)

        # Prepare a list of all monthly columns
        monthly_columns = []
        if hasattr(st.session_state, 'selected_periods'):
            for period in st.session_state.selected_periods:
                if f'{period} éŠ·å”®æ•¸é‡' in product_summary.columns:
                    monthly_columns.append(f'{period} éŠ·å”®æ•¸é‡')
                if f'{period} éŠ·å”®å°è¨ˆ' in product_summary.columns:
                    monthly_columns.append(f'{period} éŠ·å”®å°è¨ˆ')
        
        # æº–å‚™é¡¯ç¤ºçš„æ¬„ä½åˆ—è¡¨ (including inventory and monthly data)
        display_columns = ['ç”¢å“ä»£è™Ÿ', 'ç”¢å“åç¨±', 'æ•¸é‡', 'åº«å­˜', 'å–®ä½', 'å–®åƒ¹', 'å–®åƒ¹ï¼ˆæ•¸é‡ï¼‰', 'å°è¨ˆ', 'æˆæœ¬ç¸½å€¼'] + monthly_columns

        # Display the table with numeric sorting (with inventory)
        # Filter display columns to only include those that exist in the dataframe
        valid_columns = [col for col in display_columns if col in product_summary.columns]
        
        if valid_columns:
            st.dataframe(
                product_summary[valid_columns],
                use_container_width=True,
                column_config={
                    "ç”¢å“ä»£è™Ÿ": st.column_config.TextColumn("ç”¢å“ä»£è™Ÿ"),
                    "ç”¢å“åç¨±": st.column_config.TextColumn("ç”¢å“åç¨±"),
                    "æ•¸é‡": st.column_config.NumberColumn("éŠ·å”®ç¸½æ•¸é‡", format="%.0f"),
                    "åº«å­˜": st.column_config.NumberColumn("åº«å­˜æ•¸é‡", format="%.0f", help="ç›®å‰åº«å­˜æ•¸é‡ (ä¾†è‡ªBCç”¢å“è³‡æ–™)"),
                    "å–®ä½": st.column_config.TextColumn("å–®ä½"),
                    "å–®åƒ¹": st.column_config.NumberColumn(
                        "å–®åƒ¹ (å¹³å‡)",
                        format="%.2f",
                        help="ç”±æ‰€æœ‰äº¤æ˜“å–®åƒ¹åŠ ç¸½å¾Œå–å¹³å‡"
                    ),
                    "å–®åƒ¹ï¼ˆæ•¸é‡ï¼‰": st.column_config.NumberColumn(
                        "å–®åƒ¹ (æ•¸é‡)",
                        format="%.2f",
                        help="ç”±å°è¨ˆç¸½å’Œé™¤ä»¥ç¸½æ•¸é‡è¨ˆç®—"
                    ),
                    "å°è¨ˆ": st.column_config.NumberColumn(
                        "å°è¨ˆ (ç¸½å’Œ) â†“",
                        format="%.2f",
                        help="é è¨­ç”±é«˜åˆ°ä½æ’åº"
                    ),
                    "æˆæœ¬ç¸½å€¼": st.column_config.NumberColumn(
                        "æˆæœ¬ç¸½å€¼ (ç¸½å’Œ)",
                        format="%.2f",
                        help="é»æ“Šå¯ä»¥æŒ‰æ•¸å€¼å¤§å°æ’åº"
                    ),
                    **{f"{period} éŠ·å”®æ•¸é‡": st.column_config.NumberColumn(
                        f"{period} éŠ·å”®æ•¸é‡",
                        format="%.0f",
                        help=f"{period} æœŸé–“çš„éŠ·å”®æ•¸é‡"
                      ) for period in st.session_state.get('selected_periods', []) if f"{period} éŠ·å”®æ•¸é‡" in product_summary.columns},
                    **{f"{period} éŠ·å”®å°è¨ˆ": st.column_config.NumberColumn(
                        f"{period} éŠ·å”®å°è¨ˆ",
                        format="%.2f",
                        help=f"{period} æœŸé–“çš„éŠ·å”®å°è¨ˆ"
                      ) for period in st.session_state.get('selected_periods', []) if f"{period} éŠ·å”®å°è¨ˆ" in product_summary.columns}
                },
                hide_index=True
            )
        else:
            st.error("ç„¡æ³•é¡¯ç¤ºç”¢å“å½™ç¸½è¡¨ï¼šç”¢å“è³‡æ–™æ¬„ä½ä¸å®Œæ•´")
    else:
        # æº–å‚™é¡¯ç¤ºçš„æ¬„ä½åˆ—è¡¨ (without inventory)
        display_columns = ['ç”¢å“ä»£è™Ÿ', 'ç”¢å“åç¨±', 'æ•¸é‡', 'å–®ä½', 'å–®åƒ¹', 'å–®åƒ¹ï¼ˆæ•¸é‡ï¼‰', 'å°è¨ˆ', 'æˆæœ¬ç¸½å€¼']

        # Display the table with numeric sorting (without inventory)
        # Filter display columns to only include those that exist in the dataframe
        valid_columns = [col for col in display_columns if col in product_summary.columns]
        
        if valid_columns:
            st.dataframe(
                product_summary[valid_columns],
                use_container_width=True,
                column_config={
                    "ç”¢å“ä»£è™Ÿ": st.column_config.TextColumn("ç”¢å“ä»£è™Ÿ"),
                    "ç”¢å“åç¨±": st.column_config.TextColumn("ç”¢å“åç¨±"),
                    "æ•¸é‡": st.column_config.NumberColumn("æ•¸é‡", format="%.0f"),
                    "å–®ä½": st.column_config.TextColumn("å–®ä½"),
                    "å–®åƒ¹": st.column_config.NumberColumn(
                        "å–®åƒ¹ (å¹³å‡)",
                        format="%.2f",
                        help="ç”±æ‰€æœ‰äº¤æ˜“å–®åƒ¹åŠ ç¸½å¾Œå–å¹³å‡"
                    ),
                    "å–®åƒ¹ï¼ˆæ•¸é‡ï¼‰": st.column_config.NumberColumn(
                        "å–®åƒ¹ (æ•¸é‡)",
                        format="%.2f",
                        help="ç”±å°è¨ˆç¸½å’Œé™¤ä»¥ç¸½æ•¸é‡è¨ˆç®—"
                    ),
                    "å°è¨ˆ": st.column_config.NumberColumn(
                        "å°è¨ˆ (ç¸½å’Œ) â†“",
                        format="%.2f",
                        help="é è¨­ç”±é«˜åˆ°ä½æ’åº"
                    ),
                    "æˆæœ¬ç¸½å€¼": st.column_config.NumberColumn(
                        "æˆæœ¬ç¸½å€¼ (ç¸½å’Œ)",
                        format="%.2f",
                        help="é»æ“Šå¯ä»¥æŒ‰æ•¸å€¼å¤§å°æ’åº"
                    )
                },
                hide_index=True
            )
        else:
            st.error("ç„¡æ³•é¡¯ç¤ºç”¢å“å½™ç¸½è¡¨ï¼šç”¢å“è³‡æ–™æ¬„ä½ä¸å®Œæ•´")
    
    
    # Only show BC products data if available
    if bc_df is not None:
        st.markdown("---")
        st.header("BCç”¢å“è³‡æ–™")
        
        # Filter options for BC products data
        st.subheader("BCç”¢å“ç¯©é¸é¸é …")
        
        # Create 3 columns for filter widgets
        filter_col1, filter_col2, filter_col3 = st.columns(3)
        
        with filter_col1:
            # Filter by category
            if 'å¤§é¡åç¨±' in bc_df.columns and not bc_df['å¤§é¡åç¨±'].isna().all():
                all_categories = sorted(bc_df['å¤§é¡åç¨±'].dropna().unique().tolist())
                selected_categories = st.multiselect(
                    "é¸æ“‡ç”¢å“å¤§é¡:",
                    options=["å…¨éƒ¨"] + all_categories,
                    default=["å…¨éƒ¨"]
                )
                
                if "å…¨éƒ¨" not in selected_categories:
                    bc_df = bc_df[bc_df['å¤§é¡åç¨±'].isin(selected_categories)]
        
        with filter_col2:
            # Filter by vendor
            if 'å» å•†ç°¡ç¨±' in bc_df.columns and not bc_df['å» å•†ç°¡ç¨±'].isna().all():
                all_vendors = sorted(bc_df['å» å•†ç°¡ç¨±'].dropna().unique().tolist())
                selected_vendors = st.multiselect(
                    "é¸æ“‡ä¾›æ‡‰å•†:",
                    options=["å…¨éƒ¨"] + all_vendors,
                    default=["å…¨éƒ¨"]
                )
                
                if "å…¨éƒ¨" not in selected_vendors:
                    bc_df = bc_df[bc_df['å» å•†ç°¡ç¨±'].isin(selected_vendors)]
        
        with filter_col3:
            # Filter by stock availability
            stock_options = ["å…¨éƒ¨", "æœ‰åº«å­˜", "åº«å­˜ä¸è¶³", "ç„¡åº«å­˜"]
            selected_stock = st.radio("åº«å­˜ç‹€æ…‹:", stock_options)
            
            if selected_stock == "æœ‰åº«å­˜":
                bc_df = bc_df[bc_df['æ•¸é‡'] > 0]
            elif selected_stock == "åº«å­˜ä¸è¶³":
                bc_df = bc_df[(bc_df['æ•¸é‡'] > 0) & (bc_df['æ•¸é‡'] < bc_df['å®‰å…¨å­˜é‡'])]
            elif selected_stock == "ç„¡åº«å­˜":
                bc_df = bc_df[bc_df['æ•¸é‡'] <= 0]
        
        # Display BC products detail table
        st.subheader("BCç”¢å“æ˜ç´°è¡¨")
        
        # Prepare monthly columns for BC products table
        monthly_bc_columns = []
        if hasattr(st.session_state, 'selected_periods') and hasattr(st.session_state, 'monthly_sales_dfs'):
            # First, process each month's data to create a mapping of product codes to monthly sales data
            for period in st.session_state.selected_periods:
                if period in st.session_state.monthly_sales_dfs:
                    period_df = st.session_state.monthly_sales_dfs[period]
                    
                    # Process numeric columns
                    period_products = period_df.copy()
                    numeric_cols = ['æ•¸é‡', 'å°è¨ˆ']
                    for col in numeric_cols:
                        if col in period_products.columns:
                            if period_products[col].dtype == 'object':
                                period_products[col] = period_products[col].astype(str).str.replace(',', '')
                                period_products[col] = pd.to_numeric(period_products[col], errors='coerce')
                    
                    # Create period-specific aggregation
                    if 'ç”¢å“ä»£è™Ÿ' in period_products.columns:
                        try:
                            # Group by product code and aggregate
                            period_agg = {}
                            if 'æ•¸é‡' in period_products.columns:
                                period_agg['æ•¸é‡'] = 'sum'
                            if 'å°è¨ˆ' in period_products.columns:
                                period_agg['å°è¨ˆ'] = 'sum'
                            
                            if period_agg:
                                period_summary = period_products.groupby(['ç”¢å“ä»£è™Ÿ'], as_index=False).agg(period_agg)
                                
                                # Create column names for this period
                                qty_col = f'{period} éŠ·å”®æ•¸é‡'
                                rev_col = f'{period} éŠ·å”®å°è¨ˆ'
                                
                                # Add these columns to the BC dataframe
                                if 'æ•¸é‡' in period_summary.columns:
                                    bc_df[qty_col] = bc_df['ç”¢å“ä»£è™Ÿ'].map(
                                        dict(zip(period_summary['ç”¢å“ä»£è™Ÿ'], period_summary['æ•¸é‡']))
                                    ).fillna(0)
                                    monthly_bc_columns.append(qty_col)
                                
                                if 'å°è¨ˆ' in period_summary.columns:
                                    bc_df[rev_col] = bc_df['ç”¢å“ä»£è™Ÿ'].map(
                                        dict(zip(period_summary['ç”¢å“ä»£è™Ÿ'], period_summary['å°è¨ˆ']))
                                    ).fillna(0)
                                    monthly_bc_columns.append(rev_col)
                        except Exception as e:
                            st.warning(f"è™•ç†BCè¡¨æ ¼çš„ {period} æœŸé–“éŠ·å”®æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        # Merge sales data with BC product data
        if sales_df is not None and 'ç”¢å“ä»£è™Ÿ' in sales_df.columns:
            # Create sales summary if it doesn't exist yet
            if 'product_summary' not in locals():
                # Ensure numeric columns are properly converted to numeric before aggregation
                df_products = sales_df.copy()
                numeric_cols = ['æ•¸é‡', 'å°è¨ˆ', 'æˆæœ¬ç¸½å€¼']
                for col in numeric_cols:
                    if col in df_products.columns:
                        if df_products[col].dtype == 'object':
                            df_products[col] = df_products[col].astype(str).str.replace(',', '')
                            df_products[col] = pd.to_numeric(df_products[col], errors='coerce')
                
                # Separate handling for unit price
                if 'å–®åƒ¹' in df_products.columns:
                    if df_products['å–®åƒ¹'].dtype == 'object':
                        df_products['å–®åƒ¹'] = df_products['å–®åƒ¹'].astype(str).str.replace(',', '')
                        df_products['å–®åƒ¹'] = pd.to_numeric(df_products['å–®åƒ¹'], errors='coerce')
                
                # Create aggregation dictionary
                agg_dict = {}
                if 'ç”¢å“åç¨±' in df_products.columns:
                    agg_dict['ç”¢å“åç¨±'] = 'first'  # Take the first product name
                if 'æ•¸é‡' in df_products.columns:
                    agg_dict['æ•¸é‡'] = 'sum'        # Sum quantities
                if 'å–®ä½' in df_products.columns:
                    agg_dict['å–®ä½'] = 'first'      # Take the first unit
                if 'å–®åƒ¹' in df_products.columns:
                    agg_dict['å–®åƒ¹'] = 'mean'       # Average price
                if 'å°è¨ˆ' in df_products.columns:
                    agg_dict['å°è¨ˆ'] = 'sum'        # Sum subtotals
                if 'æˆæœ¬ç¸½å€¼' in df_products.columns:
                    agg_dict['æˆæœ¬ç¸½å€¼'] = 'sum'     # Sum cost values
                
                # Create product summary
                if agg_dict and 'ç”¢å“ä»£è™Ÿ' in df_products.columns:
                    product_summary = df_products.groupby(['ç”¢å“ä»£è™Ÿ'], as_index=False).agg(agg_dict)
                    
                    # Calculate å–®åƒ¹ï¼ˆæ•¸é‡ï¼‰= å°è¨ˆ / æ•¸é‡ safely
                    product_summary['å–®åƒ¹ï¼ˆæ•¸é‡ï¼‰'] = 0.0  # Default value as float
                    if 'æ•¸é‡' in product_summary.columns and 'å°è¨ˆ' in product_summary.columns:
                        mask = product_summary['æ•¸é‡'] > 0
                        if isinstance(mask, pd.Series) and mask.any():
                            result = (product_summary.loc[mask, 'å°è¨ˆ'] / product_summary.loc[mask, 'æ•¸é‡']).astype('float64')
                            product_summary.loc[mask, 'å–®åƒ¹ï¼ˆæ•¸é‡ï¼‰'] = result
            
            # Create a copy of BC dataframe to add sales data (if not already done)
            enhanced_bc_df = bc_df.copy()
            
            # Add sales columns if they don't exist
            if 'product_summary' in locals() and not product_summary.empty:
                # Create a mapping of product codes to sales data
                sales_data_map = {}
                for _, row in product_summary.iterrows():
                    product_code = row['ç”¢å“ä»£è™Ÿ']
                    sales_data = {
                        'éŠ·å”®æ•¸é‡': row.get('æ•¸é‡', 0),
                        'éŠ·å”®å–®åƒ¹': row.get('å–®åƒ¹ï¼ˆæ•¸é‡ï¼‰', 0),
                        'éŠ·å”®å°è¨ˆ': row.get('å°è¨ˆ', 0)
                    }
                    sales_data_map[product_code] = sales_data
                
                # Add sales columns to BC data
                enhanced_bc_df['éŠ·å”®æ•¸é‡'] = enhanced_bc_df['ç”¢å“ä»£è™Ÿ'].map(lambda x: sales_data_map.get(x, {}).get('éŠ·å”®æ•¸é‡', 0))
                enhanced_bc_df['éŠ·å”®å–®åƒ¹'] = enhanced_bc_df['ç”¢å“ä»£è™Ÿ'].map(lambda x: sales_data_map.get(x, {}).get('éŠ·å”®å–®åƒ¹', 0))
                enhanced_bc_df['éŠ·å”®å°è¨ˆ'] = enhanced_bc_df['ç”¢å“ä»£è™Ÿ'].map(lambda x: sales_data_map.get(x, {}).get('éŠ·å”®å°è¨ˆ', 0))
            else:
                # If no sales data exists, add empty columns
                enhanced_bc_df['éŠ·å”®æ•¸é‡'] = 0
                enhanced_bc_df['éŠ·å”®å–®åƒ¹'] = 0
                enhanced_bc_df['éŠ·å”®å°è¨ˆ'] = 0
            
            # Use the enhanced dataframe instead of the original
            bc_df = enhanced_bc_df
        
        # Allow user to select display columns
        all_columns = bc_df.columns.tolist()
        default_columns = ['ç”¢å“ä»£è™Ÿ', 'ç”¢å“åç¨±', 'æ•¸é‡', 'éŠ·å”®æ•¸é‡', 'å–®ä½', 'æˆæœ¬å–®åƒ¹', 'éŠ·å”®å–®åƒ¹', 'æˆæœ¬ç¸½åƒ¹', 'éŠ·å”®å°è¨ˆ'] + monthly_bc_columns + ['å®‰å…¨å­˜é‡', 'å» å•†ç°¡ç¨±', 'å¤§é¡åç¨±', 'ä¸­é¡åç¨±']
        selected_columns = st.multiselect(
            "é¸æ“‡é¡¯ç¤ºæ¬„ä½:",
            options=all_columns,
            default=[col for col in default_columns if col in all_columns]
        )
        
        if not selected_columns:
            selected_columns = default_columns
        
        # Sort options with added sales columns
        sort_options = {
            "ç”¢å“ä»£è™Ÿ": "ç”¢å“ä»£è™Ÿ",
            "ç”¢å“åç¨±": "ç”¢å“åç¨±",
            "åº«å­˜æ•¸é‡ (é«˜åˆ°ä½)": "æ•¸é‡",
            "åº«å­˜æ•¸é‡ (ä½åˆ°é«˜)": "æ•¸é‡_asc",
            "æˆæœ¬å–®åƒ¹ (é«˜åˆ°ä½)": "æˆæœ¬å–®åƒ¹",
            "æˆæœ¬å–®åƒ¹ (ä½åˆ°é«˜)": "æˆæœ¬å–®åƒ¹_asc",
            "æˆæœ¬ç¸½åƒ¹ (é«˜åˆ°ä½)": "æˆæœ¬ç¸½åƒ¹",
            "æˆæœ¬ç¸½åƒ¹ (ä½åˆ°é«˜)": "æˆæœ¬ç¸½åƒ¹_asc",
            "éŠ·å”®æ•¸é‡ (é«˜åˆ°ä½)": "éŠ·å”®æ•¸é‡",
            "éŠ·å”®æ•¸é‡ (ä½åˆ°é«˜)": "éŠ·å”®æ•¸é‡_asc",
            "éŠ·å”®å°è¨ˆ (é«˜åˆ°ä½)": "éŠ·å”®å°è¨ˆ",
            "éŠ·å”®å°è¨ˆ (ä½åˆ°é«˜)": "éŠ·å”®å°è¨ˆ_asc"
        }
        
        # Add monthly columns to sort options
        for col in monthly_bc_columns:
            if 'éŠ·å”®æ•¸é‡' in col:
                sort_options[f"{col} (é«˜åˆ°ä½)"] = col
                sort_options[f"{col} (ä½åˆ°é«˜)"] = f"{col}_asc"
            elif 'éŠ·å”®å°è¨ˆ' in col:
                sort_options[f"{col} (é«˜åˆ°ä½)"] = col
                sort_options[f"{col} (ä½åˆ°é«˜)"] = f"{col}_asc"
        
        sort_choice = st.selectbox("æ’åºæ–¹å¼:", list(sort_options.keys()), index=0)
        sort_column = sort_options[sort_choice]
        
        # Handle ascending/descending
        if "_asc" in sort_column:
            sort_column = sort_column.replace("_asc", "")
            ascending = True
        else:
            ascending = False
        
        # Sort and display the table with column configuration
        if sort_column in bc_df.columns:
            sorted_df = bc_df.sort_values(by=sort_column, ascending=ascending)
            st.dataframe(
                sorted_df[selected_columns], 
                use_container_width=True,
                column_config={
                    "ç”¢å“ä»£è™Ÿ": st.column_config.TextColumn("ç”¢å“ä»£è™Ÿ"),
                    "ç”¢å“åç¨±": st.column_config.TextColumn("ç”¢å“åç¨±"),
                    "æ•¸é‡": st.column_config.NumberColumn("åº«å­˜æ•¸é‡", format="%.0f"),
                    "éŠ·å”®æ•¸é‡": st.column_config.NumberColumn("éŠ·å”®ç¸½æ•¸é‡", format="%.0f", help="ä¾†è‡ªéŠ·è²¨å–®çš„éŠ·å”®æ•¸é‡ç¸½å’Œ"),
                    "å–®ä½": st.column_config.TextColumn("å–®ä½"),
                    "æˆæœ¬å–®åƒ¹": st.column_config.NumberColumn("æˆæœ¬å–®åƒ¹", format="%.2f"),
                    "éŠ·å”®å–®åƒ¹": st.column_config.NumberColumn("éŠ·å”®å–®åƒ¹", format="%.2f", help="éŠ·å”®å°è¨ˆé™¤ä»¥éŠ·å”®æ•¸é‡"),
                    "æˆæœ¬ç¸½åƒ¹": st.column_config.NumberColumn("æˆæœ¬ç¸½åƒ¹", format="%.2f"),
                    "éŠ·å”®å°è¨ˆ": st.column_config.NumberColumn("éŠ·å”®ç¸½é¡", format="%.2f", help="ä¾†è‡ªéŠ·è²¨å–®çš„éŠ·å”®å°è¨ˆç¸½å’Œ"),
                    "å®‰å…¨å­˜é‡": st.column_config.NumberColumn("å®‰å…¨å­˜é‡", format="%.0f"),
                    "å» å•†ç°¡ç¨±": st.column_config.TextColumn("å» å•†ç°¡ç¨±"),
                    "å¤§é¡åç¨±": st.column_config.TextColumn("å¤§é¡åç¨±"),
                    "ä¸­é¡åç¨±": st.column_config.TextColumn("ä¸­é¡åç¨±"),
                    **{col: st.column_config.NumberColumn(
                        col,
                        format="%.0f" if 'æ•¸é‡' in col else "%.2f",
                        help=f"{col.split(' ')[0]} æœŸé–“çš„{'éŠ·å”®æ•¸é‡' if 'æ•¸é‡' in col else 'éŠ·å”®é‡‘é¡'}"
                      ) for col in monthly_bc_columns}
                },
                hide_index=True
            )
        else:
            st.dataframe(
                bc_df[selected_columns], 
                use_container_width=True,
                column_config={
                    "ç”¢å“ä»£è™Ÿ": st.column_config.TextColumn("ç”¢å“ä»£è™Ÿ"),
                    "ç”¢å“åç¨±": st.column_config.TextColumn("ç”¢å“åç¨±"),
                    "æ•¸é‡": st.column_config.NumberColumn("åº«å­˜æ•¸é‡", format="%.0f"),
                    "éŠ·å”®æ•¸é‡": st.column_config.NumberColumn("éŠ·å”®ç¸½æ•¸é‡", format="%.0f", help="ä¾†è‡ªéŠ·è²¨å–®çš„éŠ·å”®æ•¸é‡ç¸½å’Œ"),
                    "å–®ä½": st.column_config.TextColumn("å–®ä½"),
                    "æˆæœ¬å–®åƒ¹": st.column_config.NumberColumn("æˆæœ¬å–®åƒ¹", format="%.2f"),
                    "éŠ·å”®å–®åƒ¹": st.column_config.NumberColumn("éŠ·å”®å–®åƒ¹", format="%.2f", help="éŠ·å”®å°è¨ˆé™¤ä»¥éŠ·å”®æ•¸é‡"),
                    "æˆæœ¬ç¸½åƒ¹": st.column_config.NumberColumn("æˆæœ¬ç¸½åƒ¹", format="%.2f"),
                    "éŠ·å”®å°è¨ˆ": st.column_config.NumberColumn("éŠ·å”®ç¸½é¡", format="%.2f", help="ä¾†è‡ªéŠ·è²¨å–®çš„éŠ·å”®å°è¨ˆç¸½å’Œ"),
                    "å®‰å…¨å­˜é‡": st.column_config.NumberColumn("å®‰å…¨å­˜é‡", format="%.0f"),
                    "å» å•†ç°¡ç¨±": st.column_config.TextColumn("å» å•†ç°¡ç¨±"),
                    "å¤§é¡åç¨±": st.column_config.TextColumn("å¤§é¡åç¨±"),
                    "ä¸­é¡åç¨±": st.column_config.TextColumn("ä¸­é¡åç¨±"),
                    **{col: st.column_config.NumberColumn(
                        col,
                        format="%.0f" if 'æ•¸é‡' in col else "%.2f",
                        help=f"{col.split(' ')[0]} æœŸé–“çš„{'éŠ·å”®æ•¸é‡' if 'æ•¸é‡' in col else 'éŠ·å”®é‡‘é¡'}"
                      ) for col in monthly_bc_columns}
                },
                hide_index=True
            )

# Run the module when executed directly
if __name__ == "__main__":
    sales_df, period_display, bc_df, file_date = run_integrated_analysis()
    display_integrated_dashboard(sales_df, period_display, bc_df, file_date)